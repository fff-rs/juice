<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `rcudnn/cudnn/src/api/activation.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>activation.rs - source</title><link rel="stylesheet" type="text/css" href="../../../normalize.css"><link rel="stylesheet" type="text/css" href="../../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" type="text/css" href="../../../light.css"  id="themeStyle"><link rel="stylesheet" type="text/css" href="../../../dark.css" disabled ><link rel="stylesheet" type="text/css" href="../../../ayu.css" disabled ><script id="default-settings"></script><script src="../../../storage.js"></script><script src="../../../crates.js"></script><noscript><link rel="stylesheet" href="../../../noscript.css"></noscript><link rel="icon" type="image/svg+xml" href="../../../favicon.svg">
<link rel="alternate icon" type="image/png" href="../../../favicon-16x16.png">
<link rel="alternate icon" type="image/png" href="../../../favicon-32x32.png"><style type="text/css">#crate-search{background-image:url("../../../down-arrow.svg");}</style></head><body class="rustdoc source"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><div class="sidebar-menu" role="button">&#9776;</div><a href='../../../rcudnn/index.html'><div class='logo-container rust-logo'><img src='../../../rust-logo.png' alt='logo'></div></a></nav><div class="theme-picker"><button id="theme-picker" aria-label="Pick another theme!" aria-haspopup="menu" title="themes"><img src="../../../brush.svg" width="18" height="18" alt="Pick another theme!"></button><div id="theme-choices" role="menu"></div></div><nav class="sub"><form class="search-form"><div class="search-container"><div><select id="crate-search"><option value="All crates">All crates</option></select><input class="search-input" name="search" disabled autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"></div><button type="button" id="help-button" title="help">?</button><a id="settings-menu" href="../../../settings.html" title="settings"><img src="../../../wheel.svg" width="18" height="18" alt="Change settings"></a></div></form></nav><section id="main" class="content"><div class="example-wrap"><pre class="line-numbers"><span id="1">  1</span>
<span id="2">  2</span>
<span id="3">  3</span>
<span id="4">  4</span>
<span id="5">  5</span>
<span id="6">  6</span>
<span id="7">  7</span>
<span id="8">  8</span>
<span id="9">  9</span>
<span id="10"> 10</span>
<span id="11"> 11</span>
<span id="12"> 12</span>
<span id="13"> 13</span>
<span id="14"> 14</span>
<span id="15"> 15</span>
<span id="16"> 16</span>
<span id="17"> 17</span>
<span id="18"> 18</span>
<span id="19"> 19</span>
<span id="20"> 20</span>
<span id="21"> 21</span>
<span id="22"> 22</span>
<span id="23"> 23</span>
<span id="24"> 24</span>
<span id="25"> 25</span>
<span id="26"> 26</span>
<span id="27"> 27</span>
<span id="28"> 28</span>
<span id="29"> 29</span>
<span id="30"> 30</span>
<span id="31"> 31</span>
<span id="32"> 32</span>
<span id="33"> 33</span>
<span id="34"> 34</span>
<span id="35"> 35</span>
<span id="36"> 36</span>
<span id="37"> 37</span>
<span id="38"> 38</span>
<span id="39"> 39</span>
<span id="40"> 40</span>
<span id="41"> 41</span>
<span id="42"> 42</span>
<span id="43"> 43</span>
<span id="44"> 44</span>
<span id="45"> 45</span>
<span id="46"> 46</span>
<span id="47"> 47</span>
<span id="48"> 48</span>
<span id="49"> 49</span>
<span id="50"> 50</span>
<span id="51"> 51</span>
<span id="52"> 52</span>
<span id="53"> 53</span>
<span id="54"> 54</span>
<span id="55"> 55</span>
<span id="56"> 56</span>
<span id="57"> 57</span>
<span id="58"> 58</span>
<span id="59"> 59</span>
<span id="60"> 60</span>
<span id="61"> 61</span>
<span id="62"> 62</span>
<span id="63"> 63</span>
<span id="64"> 64</span>
<span id="65"> 65</span>
<span id="66"> 66</span>
<span id="67"> 67</span>
<span id="68"> 68</span>
<span id="69"> 69</span>
<span id="70"> 70</span>
<span id="71"> 71</span>
<span id="72"> 72</span>
<span id="73"> 73</span>
<span id="74"> 74</span>
<span id="75"> 75</span>
<span id="76"> 76</span>
<span id="77"> 77</span>
<span id="78"> 78</span>
<span id="79"> 79</span>
<span id="80"> 80</span>
<span id="81"> 81</span>
<span id="82"> 82</span>
<span id="83"> 83</span>
<span id="84"> 84</span>
<span id="85"> 85</span>
<span id="86"> 86</span>
<span id="87"> 87</span>
<span id="88"> 88</span>
<span id="89"> 89</span>
<span id="90"> 90</span>
<span id="91"> 91</span>
<span id="92"> 92</span>
<span id="93"> 93</span>
<span id="94"> 94</span>
<span id="95"> 95</span>
<span id="96"> 96</span>
<span id="97"> 97</span>
<span id="98"> 98</span>
<span id="99"> 99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
</pre><pre class="rust">
<span class="doccomment">//! Provides the activation functionality from the CUDA cuDNN API.</span>

<span class="kw">use</span> <span class="kw">crate</span><span class="ident">::ffi</span>::<span class="kw-2">*</span>;
<span class="kw">use</span> <span class="kw">crate</span>::{<span class="ident">Error</span>, <span class="ident">API</span>};

<span class="kw">impl</span> <span class="ident">API</span> {
    <span class="doccomment">/// Create a generic CUDA cuDNN ActivationDescriptor.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">create_activation_descriptor</span>() <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">cudnnActivationDescriptor_t</span>, <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">unsafe</span> { <span class="ident">API::ffi_create_activation_descriptor</span>() }
    }

    <span class="doccomment">/// Destroys a CUDA cuDNN Activation Descriptor.</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// Should be called when freeing a CUDA::Descriptor to not trash up the CUDA device.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">destroy_activation_descriptor</span>(<span class="ident">desc</span>: <span class="ident">cudnnActivationDescriptor_t</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">unsafe</span> { <span class="ident">API::ffi_destroy_activation_descriptor</span>(<span class="ident">desc</span>) }
    }

    <span class="doccomment">/// Initializes a generic CUDA cuDNN Activation Descriptor with specific properties.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">set_activation_descriptor</span>(
        <span class="ident">desc</span>: <span class="ident">cudnnActivationDescriptor_t</span>,
        <span class="ident">mode</span>: <span class="ident">cudnnActivationMode_t</span>,
        <span class="ident">relu_nan_opt</span>: <span class="ident">cudnnNanPropagation_t</span>,
        <span class="ident">relu_ceiling</span>: <span class="ident">f64</span>,
    ) <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">unsafe</span> { <span class="ident">API::ffi_set_activation_descriptor</span>(<span class="ident">desc</span>, <span class="ident">mode</span>, <span class="ident">relu_nan_opt</span>, <span class="ident">relu_ceiling</span>) }
    }

    <span class="doccomment">/// Computes an activation forward function.</span>
    <span class="attribute">#[<span class="ident">allow</span>(<span class="ident">clippy::too_many_arguments</span>)]</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">activation_forward</span>(
        <span class="ident">handle</span>: <span class="ident">cudnnHandle_t</span>,
        <span class="ident">activation_desc</span>: <span class="ident">cudnnActivationDescriptor_t</span>,
        <span class="ident">alpha</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">x_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">x</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">beta</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">y_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">y</span>: <span class="kw-2">*</span><span class="kw-2">mut</span> <span class="ident">::libc::c_void</span>,
    ) <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">unsafe</span> {
            <span class="ident">API::ffi_activation_forward</span>(<span class="ident">handle</span>, <span class="ident">activation_desc</span>, <span class="ident">alpha</span>, <span class="ident">x_desc</span>, <span class="ident">x</span>, <span class="ident">beta</span>, <span class="ident">y_desc</span>, <span class="ident">y</span>)
        }
    }

    <span class="doccomment">/// Computes an activation backward function.</span>
    <span class="attribute">#[<span class="ident">allow</span>(<span class="ident">clippy::too_many_arguments</span>)]</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">activation_backward</span>(
        <span class="ident">handle</span>: <span class="ident">cudnnHandle_t</span>,
        <span class="ident">activation_desc</span>: <span class="ident">cudnnActivationDescriptor_t</span>,
        <span class="ident">alpha</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">y_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">y</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">dy_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">dy</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">beta</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">x_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">x</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">dx_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">dx</span>: <span class="kw-2">*</span><span class="kw-2">mut</span> <span class="ident">::libc::c_void</span>,
    ) <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">unsafe</span> {
            <span class="ident">API::ffi_activation_backward</span>(
                <span class="ident">handle</span>,
                <span class="ident">activation_desc</span>,
                <span class="ident">alpha</span>,
                <span class="ident">y_desc</span>,
                <span class="ident">y</span>,
                <span class="ident">dy_desc</span>,
                <span class="ident">dy</span>,
                <span class="ident">beta</span>,
                <span class="ident">x_desc</span>,
                <span class="ident">x</span>,
                <span class="ident">dx_desc</span>,
                <span class="ident">dx</span>,
            )
        }
    }

    <span class="attribute">#[<span class="ident">allow</span>(<span class="ident">clippy::too_many_arguments</span>)]</span>
    <span class="kw">unsafe</span> <span class="kw">fn</span> <span class="ident">ffi_activation_forward</span>(
        <span class="ident">handle</span>: <span class="ident">cudnnHandle_t</span>,
        <span class="ident">activation_desc</span>: <span class="ident">cudnnActivationDescriptor_t</span>,
        <span class="ident">alpha</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">src_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">src_data</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">beta</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">dest_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">dest_data</span>: <span class="kw-2">*</span><span class="kw-2">mut</span> <span class="ident">::libc::c_void</span>,
    ) <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">match</span> <span class="ident">cudnnActivationForward</span>(<span class="ident">handle</span>, <span class="ident">activation_desc</span>, <span class="ident">alpha</span>, <span class="ident">src_desc</span>, <span class="ident">src_data</span>, <span class="ident">beta</span>, <span class="ident">dest_desc</span>, <span class="ident">dest_data</span>) {
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_SUCCESS</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Ok</span>(()),
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_BAD_PARAM</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::BadParam</span>(<span class="string">&quot;`mode` is invalid or dimensions of input and output tensor differ or `data_type` or strides of the tensors differ.&quot;</span>)),
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_EXECUTION_FAILED</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::ExecutionFailed</span>(<span class="string">&quot;Execution failed to launch on GPU.&quot;</span>)),
           <span class="ident">status</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::Unknown</span>(<span class="string">&quot;Unable to compute activation forward.&quot;</span>, <span class="ident">status</span> <span class="kw">as</span> <span class="ident">i32</span> <span class="kw">as</span> <span class="ident">u64</span>)),

        }
    }

    <span class="attribute">#[<span class="ident">allow</span>(<span class="ident">clippy::too_many_arguments</span>)]</span>
    <span class="kw">unsafe</span> <span class="kw">fn</span> <span class="ident">ffi_activation_backward</span>(
        <span class="ident">handle</span>: <span class="ident">cudnnHandle_t</span>,
        <span class="ident">activation_desc</span>: <span class="ident">cudnnActivationDescriptor_t</span>,
        <span class="ident">alpha</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">src_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">src_data</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">src_diff_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">src_diff_data</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">beta</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">dest_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">dest_data</span>: <span class="kw-2">*</span><span class="kw">const</span> <span class="ident">::libc::c_void</span>,
        <span class="ident">dest_diff_desc</span>: <span class="ident">cudnnTensorDescriptor_t</span>,
        <span class="ident">dest_diff_data</span>: <span class="kw-2">*</span><span class="kw-2">mut</span> <span class="ident">::libc::c_void</span>,
    ) <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">match</span> <span class="ident">cudnnActivationBackward</span>(<span class="ident">handle</span>, <span class="ident">activation_desc</span>, <span class="ident">alpha</span>, <span class="ident">src_desc</span>, <span class="ident">src_data</span>, <span class="ident">src_diff_desc</span>, <span class="ident">src_diff_data</span>, <span class="ident">dest_desc</span>, <span class="ident">dest_data</span>, <span class="ident">beta</span>, <span class="ident">dest_diff_desc</span>, <span class="ident">dest_diff_data</span>) {
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_SUCCESS</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Ok</span>(()),
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_BAD_PARAM</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::BadParam</span>(<span class="string">&quot;`mode` is invalid or dimensions of input and output tensor differ or `data_type` or strides of the tensors differ.&quot;</span>)),
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_NOT_SUPPORTED</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::NotSupported</span>(<span class="string">&quot;`mode` is invalid or dimensions of input and output tensor differ or `data_type` or strides of the tensors differ.&quot;</span>)),
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_EXECUTION_FAILED</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::ExecutionFailed</span>(<span class="string">&quot;Execution failed to launch on GPU.&quot;</span>)),
           <span class="ident">status</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::Unknown</span>(<span class="string">&quot;Unable to compute activation backward.&quot;</span>, <span class="ident">status</span> <span class="kw">as</span> <span class="ident">i32</span> <span class="kw">as</span> <span class="ident">u64</span>)),

        }
    }

    <span class="kw">unsafe</span> <span class="kw">fn</span> <span class="ident">ffi_create_activation_descriptor</span>() <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span><span class="ident">cudnnActivationDescriptor_t</span>, <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">desc</span>: <span class="ident">cudnnActivationDescriptor_t</span> <span class="op">=</span> <span class="ident">::std::ptr::null_mut</span>();
        <span class="kw">match</span> <span class="ident">cudnnCreateActivationDescriptor</span>(<span class="kw-2">&amp;</span><span class="kw-2">mut</span> <span class="ident">desc</span>) {
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_SUCCESS</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Ok</span>(<span class="ident">desc</span>),
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_ALLOC_FAILED</span> <span class="op">=</span><span class="op">&gt;</span> {
                <span class="prelude-val">Err</span>(<span class="ident">Error::AllocFailed</span>(<span class="string">&quot;The resources could not be allocated.&quot;</span>))
            }
            <span class="ident">status</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::Unknown</span>(
                <span class="string">&quot;Unable to create generic CUDA cuDNN Activation Descriptor.&quot;</span>,
                <span class="ident">status</span> <span class="kw">as</span> <span class="ident">i32</span> <span class="kw">as</span> <span class="ident">u64</span>,
            )),
        }
    }

    <span class="kw">unsafe</span> <span class="kw">fn</span> <span class="ident">ffi_destroy_activation_descriptor</span>(
        <span class="ident">desc</span>: <span class="ident">cudnnActivationDescriptor_t</span>,
    ) <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">match</span> <span class="ident">cudnnDestroyActivationDescriptor</span>(<span class="ident">desc</span>) {
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_SUCCESS</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Ok</span>(()),
            <span class="ident">status</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::Unknown</span>(
                <span class="string">&quot;Unable to destroy CUDA cuDNN Activation Descriptor.&quot;</span>,
                <span class="ident">status</span> <span class="kw">as</span> <span class="ident">i32</span> <span class="kw">as</span> <span class="ident">u64</span>,
            )),
        }
    }

    <span class="kw">unsafe</span> <span class="kw">fn</span> <span class="ident">ffi_set_activation_descriptor</span>(
        <span class="ident">desc</span>: <span class="ident">cudnnActivationDescriptor_t</span>,
        <span class="ident">mode</span>: <span class="ident">cudnnActivationMode_t</span>,
        <span class="ident">relu_nan_opt</span>: <span class="ident">cudnnNanPropagation_t</span>,
        <span class="ident">relu_ceiling</span>: <span class="ident">f64</span>,
    ) <span class="op">-</span><span class="op">&gt;</span> <span class="prelude-ty">Result</span><span class="op">&lt;</span>(), <span class="ident">Error</span><span class="op">&gt;</span> {
        <span class="kw">match</span> <span class="ident">cudnnSetActivationDescriptor</span>(<span class="ident">desc</span>, <span class="ident">mode</span>, <span class="ident">relu_nan_opt</span>, <span class="ident">relu_ceiling</span>) {
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_SUCCESS</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Ok</span>(()),
            <span class="ident">cudnnStatus_t::CUDNN_STATUS_BAD_PARAM</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::BadParam</span>(
                <span class="string">&quot;`window_dim_a`, `padding_a` or `stride_a` has negative element or invalid `mode`.&quot;</span>,
            )), <span class="comment">// FIXME</span>
            <span class="ident">status</span> <span class="op">=</span><span class="op">&gt;</span> <span class="prelude-val">Err</span>(<span class="ident">Error::Unknown</span>(
                <span class="string">&quot;Unable to set CUDA cuDNN Activation Descriptor.&quot;</span>,
                <span class="ident">status</span> <span class="kw">as</span> <span class="ident">i32</span> <span class="kw">as</span> <span class="ident">u64</span>,
            )),
        }
    }
}
</pre></div>
</section><section id="search" class="content hidden"></section><div id="rustdoc-vars" data-root-path="../../../" data-current-crate="rcudnn" data-search-index-js="../../../search-index.js" data-search-js="../../../search.js"></div><script src="../../../main.js"></script><script src="../../../source-script.js"></script><script src="../../../source-files.js"></script></body></html>