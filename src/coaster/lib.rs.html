<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source to the Rust file `coaster/src/lib.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>lib.rs.html -- source</title><link rel="stylesheet" type="text/css" href="../../normalize.css"><link rel="stylesheet" type="text/css" href="../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" type="text/css" href="../../dark.css"><link rel="stylesheet" type="text/css" href="../../light.css" id="themeStyle"><script src="../../storage.js"></script><noscript><link rel="stylesheet" href="../../noscript.css"></noscript><link rel="shortcut icon" href="../../favicon.ico"><style type="text/css">#crate-search{background-image:url("../../down-arrow.svg");}</style></head><body class="rustdoc source"><!--[if lte IE 8]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><div class="sidebar-menu">&#9776;</div><a href='../../coaster/index.html'><div class='logo-container'><img src='../../rust-logo.png' alt='logo'></div></a></nav><div class="theme-picker"><button id="theme-picker" aria-label="Pick another theme!"><img src="../../brush.svg" width="18" alt="Pick another theme!"></button><div id="theme-choices"></div></div><script src="../../theme.js"></script><nav class="sub"><form class="search-form"><div class="search-container"><div><select id="crate-search"><option value="All crates">All crates</option></select><input class="search-input" name="search" disabled autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"></div><a id="settings-menu" href="../../settings.html"><img src="../../wheel.svg" width="18" alt="Change settings"></a></div></form></nav><section id="main" class="content"><pre class="line-numbers"><span id="1">  1</span>
<span id="2">  2</span>
<span id="3">  3</span>
<span id="4">  4</span>
<span id="5">  5</span>
<span id="6">  6</span>
<span id="7">  7</span>
<span id="8">  8</span>
<span id="9">  9</span>
<span id="10"> 10</span>
<span id="11"> 11</span>
<span id="12"> 12</span>
<span id="13"> 13</span>
<span id="14"> 14</span>
<span id="15"> 15</span>
<span id="16"> 16</span>
<span id="17"> 17</span>
<span id="18"> 18</span>
<span id="19"> 19</span>
<span id="20"> 20</span>
<span id="21"> 21</span>
<span id="22"> 22</span>
<span id="23"> 23</span>
<span id="24"> 24</span>
<span id="25"> 25</span>
<span id="26"> 26</span>
<span id="27"> 27</span>
<span id="28"> 28</span>
<span id="29"> 29</span>
<span id="30"> 30</span>
<span id="31"> 31</span>
<span id="32"> 32</span>
<span id="33"> 33</span>
<span id="34"> 34</span>
<span id="35"> 35</span>
<span id="36"> 36</span>
<span id="37"> 37</span>
<span id="38"> 38</span>
<span id="39"> 39</span>
<span id="40"> 40</span>
<span id="41"> 41</span>
<span id="42"> 42</span>
<span id="43"> 43</span>
<span id="44"> 44</span>
<span id="45"> 45</span>
<span id="46"> 46</span>
<span id="47"> 47</span>
<span id="48"> 48</span>
<span id="49"> 49</span>
<span id="50"> 50</span>
<span id="51"> 51</span>
<span id="52"> 52</span>
<span id="53"> 53</span>
<span id="54"> 54</span>
<span id="55"> 55</span>
<span id="56"> 56</span>
<span id="57"> 57</span>
<span id="58"> 58</span>
<span id="59"> 59</span>
<span id="60"> 60</span>
<span id="61"> 61</span>
<span id="62"> 62</span>
<span id="63"> 63</span>
<span id="64"> 64</span>
<span id="65"> 65</span>
<span id="66"> 66</span>
<span id="67"> 67</span>
<span id="68"> 68</span>
<span id="69"> 69</span>
<span id="70"> 70</span>
<span id="71"> 71</span>
<span id="72"> 72</span>
<span id="73"> 73</span>
<span id="74"> 74</span>
<span id="75"> 75</span>
<span id="76"> 76</span>
<span id="77"> 77</span>
<span id="78"> 78</span>
<span id="79"> 79</span>
<span id="80"> 80</span>
<span id="81"> 81</span>
<span id="82"> 82</span>
<span id="83"> 83</span>
<span id="84"> 84</span>
<span id="85"> 85</span>
<span id="86"> 86</span>
<span id="87"> 87</span>
<span id="88"> 88</span>
<span id="89"> 89</span>
<span id="90"> 90</span>
<span id="91"> 91</span>
<span id="92"> 92</span>
<span id="93"> 93</span>
<span id="94"> 94</span>
<span id="95"> 95</span>
<span id="96"> 96</span>
<span id="97"> 97</span>
<span id="98"> 98</span>
<span id="99"> 99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
</pre><div class="example-wrap"><pre class="rust ">
<span class="doccomment">//! Provides a simple and unified API to run fast and highly parallel computations on different</span>
<span class="doccomment">//! devices such as CPUs and GPUs, accross different computation languages such as OpenCL and</span>
<span class="doccomment">//! CUDA and allows you to swap your backend on run-time.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Coaster was started at [Autumn][autumn] to create an easy and performant abstraction over</span>
<span class="doccomment">//! different backends for the Machine Intelligence Framework [Leaf][leaf], with no hard</span>
<span class="doccomment">//! dependency on any driver or libraries so that it can easily be used without the need for a</span>
<span class="doccomment">//! long and painful build process.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Abstract</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Code often is executed on the native CPU, but could be executed on other devices such as GPUs</span>
<span class="doccomment">//! and Accelerators as well. These devices are accessable through frameworks like OpenCL and CUDA</span>
<span class="doccomment">//! but have a more complicated interfaces than your every-day native CPU</span>
<span class="doccomment">//! which makes the use of these devices a painful experience. Some of the pain points, when</span>
<span class="doccomment">//! writing such device code, are:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! * non-portable: frameworks have different interfaces, devices support different versions and</span>
<span class="doccomment">//! machines might have different hardware - all this leads to code that will be executable only on</span>
<span class="doccomment">//! a very specific set of machines and platforms.</span>
<span class="doccomment">//! * steep learning curve: executing code on a device through a framework is quite different to</span>
<span class="doccomment">//! running code on the native CPU and comes with a lot of hurdles. OpenCLs 1.2 specification for</span>
<span class="doccomment">//! example has close to 400 pages.</span>
<span class="doccomment">//! * custom code: integrating support for devices into your project, requires the need for writing</span>
<span class="doccomment">//! a lot of custom code e.g. kernels, memory management, genereal business logic.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! But writing code for devices would often be a good choice as these devices can execute many</span>
<span class="doccomment">//! operations a lot faster than the native CPUs. GPUs for example can execute operations roughly</span>
<span class="doccomment">//! one to two orders of magnitudes faster, thanks to better support of parallelizing operations.</span>
<span class="doccomment">//! OpenCL and CUDA make parallelizing operations super easy.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! With Coaster we eleminate the pain points of writing device code, so you can run your code</span>
<span class="doccomment">//! like any other Rust code, don&#39;t need to learn about kernels, events, or memory</span>
<span class="doccomment">//! synchronization, and can deploy your code with ease to servers, desktops or mobiles and</span>
<span class="doccomment">//! your code will make full use of the underlying hardware.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Architecture</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! The single entry point of Coaster is a [Backend][backend]. A Backend is agnostic over the [Device][device] it</span>
<span class="doccomment">//! runs [Operations][operation] on. In order to be agnostic over the Device, such as native host CPU, GPUs,</span>
<span class="doccomment">//! Accelerators or other types of [Hardware][hardware], the Backend needs to be agnostic over the</span>
<span class="doccomment">//! [Framework][framework] as well. A Framework is a computation language such as OpenCL, Cuda or the native programming</span>
<span class="doccomment">//! language. The Framework is important, as it provides us with the interface to turn Hardware into Devices and</span>
<span class="doccomment">//! therefore, among other things, execute Operations on the created Device. With a Framework, we get access to Hardware</span>
<span class="doccomment">//! as long as the Hardware supports the Framework. As different vendors of Hardware use different</span>
<span class="doccomment">//! Frameworks, it becomes important that the Backend is agnostic over the Framework. This allows us to</span>
<span class="doccomment">//! run computations on any machine such as servers, desktops and mobiles without the need to worry about what</span>
<span class="doccomment">//! Hardware is available on the machine. That gives us the freedom to write code once and deploy it on different</span>
<span class="doccomment">//! machines where it will execute on the most potent Hardware by default.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Operations get introduced by a [Plugin][plugin]. A Plugin extends your Backend with ready-to-execute Operations.</span>
<span class="doccomment">//! All you need to do is provide these Coaster Plugin crates alongside the Coaster crate in your Cargo</span>
<span class="doccomment">//! file. Your Backend will then be extended with the operations provided by the Plugin. The interface is just common</span>
<span class="doccomment">//! Rust e.g. to execute the dot product operation of the [Coaster-BLAS][coaster-blas] Plugin,</span>
<span class="doccomment">//! we can simply call `backend.dot(...)`. Whether or not the dot Operation is executed on, e.g.</span>
<span class="doccomment">//! one or many GPUs or CPUs, depends solely on how you configured the Backend. If you did not further specify which</span>
<span class="doccomment">//! Framework and Hardware to use, it depends solely on the machine you execute the dot Operation on. The concept of Operations</span>
<span class="doccomment">//! has one more component - the [Binary][binary]. As opposed to executing code on the native CPU - devices need</span>
<span class="doccomment">//! to compile and build the Operation manually at run-time, which makes up a significant part of a Framework. We need</span>
<span class="doccomment">//! an initializable instance for holding the state and compiled Operations, wich the Binary is good for.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! The last piece of Coaster is the [Memory][memory]. A Operation happens over data, but this data needs to be</span>
<span class="doccomment">//! accessable by the device on which the Operation is executed. The process is occurs often, that memory space needs</span>
<span class="doccomment">//! to be allocated on the device and then in a later step, synced from the host to the device or from</span>
<span class="doccomment">//! the device back to the host. Thanks to [Tensor][tensor] we do not have to care about memory management</span>
<span class="doccomment">//! between devices for the execution of Operations. Tensor tracks and automatically manages data and it&#39;s memory</span>
<span class="doccomment">//! accross devices, which is often the host and the Device. But it can also be passed around to different Backends.</span>
<span class="doccomment">//! Operations take Tensors as arguments and handle the synchronization and allocation for you.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Examples</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! This example requires the Coaster NN Plugin, for Neural Network related operations, to work.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```ignore</span>
<span class="doccomment">//! extern crate coaster as co;</span>
<span class="doccomment">//! extern crate coaster_nn as nn;</span>
<span class="doccomment">//! use co::prelude::*;</span>
<span class="doccomment">//! use nn::*;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn write_to_memory&lt;T: Copy&gt;(mem: &amp;mut FlatBox, data: &amp;[T]) {</span>
<span class="doccomment">//!         let mut mem_buffer = mem.as_mut_slice::&lt;T&gt;();</span>
<span class="doccomment">//!         for (index, datum) in data.iter().enumerate() {</span>
<span class="doccomment">//!             mem_buffer[index] = *datum;</span>
<span class="doccomment">//!         }</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! fn main() {</span>
<span class="doccomment">//!     // Initialize a CUDA Backend.</span>
<span class="doccomment">//!     let backend = Backend::&lt;Cuda&gt;::default().unwrap();</span>
<span class="doccomment">//!     // Initialize two SharedTensors.</span>
<span class="doccomment">//!     let mut x = SharedTensor::&lt;f32&gt;::new(&amp;(1, 1, 3)).unwrap();</span>
<span class="doccomment">//!     let mut result = SharedTensor::&lt;f32&gt;::new(&amp;(1, 1, 3)).unwrap();</span>
<span class="doccomment">//!     // Fill `x` with some data.</span>
<span class="doccomment">//!     let payload: &amp;[f32] = &amp;::std::iter::repeat(1f32).take(x.capacity()).collect::&lt;Vec&lt;f32&gt;&gt;();</span>
<span class="doccomment">//!     let native = Backend::&lt;Native&gt;::default().unwrap();</span>
<span class="doccomment">//!     write_to_memory(x.get_mut(native.device()).unwrap(), payload); // Write to native host memory.</span>
<span class="doccomment">//!     // Run the sigmoid operation, provided by the NN Plugin, on your CUDA enabled GPU.</span>
<span class="doccomment">//!     backend.sigmoid(&amp;mut x, &amp;mut result).unwrap();</span>
<span class="doccomment">//!     // See the result.</span>
<span class="doccomment">//!     println!(&quot;{:?}&quot;, result.get(native.device()).unwrap().as_native().unwrap().as_slice::&lt;f32&gt;());</span>
<span class="doccomment">//! }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Development</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! At the moment Coaster itself will provide Rust APIs for the important frameworks - OpenCL</span>
<span class="doccomment">//! and CUDA. One step we are looking out for is to seperate OpenCL and CUDA into their own crate.</span>
<span class="doccomment">//! Something similar to [Glium][glium].</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Every operation exposed via a Plugin and implemented on the backend, should take as the last argument an</span>
<span class="doccomment">//! `Option&lt;OperationConfig&gt;` to specify custom parallelisation behaviour and tracking the operation via events.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! When initializing a new Backend from a BackendConfig you might not want to specify the Framework, which is currently</span>
<span class="doccomment">//! mandatory. Leaving it blank, the Backend would try to use the most potent Framework given the underlying hardware,</span>
<span class="doccomment">//! which would be probably in this order Cuda -&gt; OpenCL -&gt; Native. The setup might take longer, as every framework</span>
<span class="doccomment">//! needs to be checked, and devices be loaded in order to identify the best setup. But this would allow, that you</span>
<span class="doccomment">//! really could deploy a Coaster-backed application to almost any hardware - server, desktops, mobiles.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! [autumn]: http://autumnai.com</span>
<span class="doccomment">//! [leaf]: https://github.com/spearow/leaf</span>
<span class="doccomment">//! [glium]: https://github.com/tomaka/glium</span>
<span class="doccomment">//! [backend]: ./backend/index.html</span>
<span class="doccomment">//! [device]: ./device/index.html</span>
<span class="doccomment">//! [binary]: ./binary/index.html</span>
<span class="doccomment">//! [operation]: ./operation/index.html</span>
<span class="doccomment">//! [hardware]: ./hardware/index.html</span>
<span class="doccomment">//! [framework]: ./framework/index.html</span>
<span class="doccomment">//! [plugin]: ./plugin/index.html</span>
<span class="doccomment">//! [coaster-blas]: https://github.com/spearow/coaster-blas</span>
<span class="doccomment">//! [memory]: ./memory/index.html</span>
<span class="doccomment">//! [tensor]: ./tensor/index.html</span>
<span class="attribute">#![<span class="ident">allow</span>(<span class="ident">dead_code</span>)]</span>
<span class="attribute">#![<span class="ident">deny</span>(
    <span class="ident">clippy</span>::<span class="ident">missing_docs</span>,
    <span class="ident">clippy</span>::<span class="ident">missing_debug_implementations</span>,
    <span class="ident">clippy</span>::<span class="ident">missing_copy_implementations</span>,
    <span class="ident">clippy</span>::<span class="ident">trivial_casts</span>,
    <span class="ident">clippy</span>::<span class="ident">trivial_numeric_casts</span>,
    <span class="ident">clippy</span>::<span class="ident">unsafe_code</span>,
    <span class="ident">clippy</span>::<span class="ident">unused_import_braces</span>,
    <span class="ident">clippy</span>::<span class="ident">unused_qualifications</span>,
    <span class="ident">clippy</span>::<span class="ident">complexity</span>
)]</span>

<span class="attribute">#![<span class="ident">cfg_attr</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;unstable_alloc&quot;</span>, <span class="ident">feature</span>(<span class="ident">alloc</span>))]</span>
<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;unstable_alloc&quot;</span>)]</span>
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">alloc</span>;

<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">libc</span>;
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">bitflags</span>;
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">enum_primitive</span>;
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">lazy_static</span>;

<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;opencl&quot;</span>)]</span>
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">regex</span>;
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">num</span>;
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">byteorder</span>;

<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">backend</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">device</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">hardware</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">framework</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">frameworks</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">tensor</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">operation</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">binary</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">error</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">plugin</span>;

<span class="comment">// These will be exported with the prelude.</span>
<span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">backend</span>::<span class="kw-2">*</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">device</span>::{<span class="ident">IDevice</span>, <span class="ident">IMemory</span>};
<span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">hardware</span>::{<span class="ident">IHardware</span>, <span class="ident">HardwareType</span>};
<span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">framework</span>::<span class="ident">IFramework</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">tensor</span>::{<span class="ident">SharedTensor</span>, <span class="ident">TensorDesc</span>, <span class="ident">ITensorDesc</span>, <span class="ident">IntoTensorDesc</span>};
<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;native&quot;</span>)]</span>
<span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">frameworks</span>::<span class="ident">Native</span>;
<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;cuda&quot;</span>)]</span>
<span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">frameworks</span>::<span class="ident">Cuda</span>;
<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;cuda&quot;</span>)]</span>
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">rcudnn</span> <span class="kw">as</span> <span class="ident">cudnn</span>;
<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;cuda&quot;</span>)]</span>
<span class="kw">extern</span> <span class="kw">crate</span> <span class="ident">rcublas</span> <span class="kw">as</span> <span class="ident">cublas</span>;

<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;opencl&quot;</span>)]</span>
<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">frameworks</span>::<span class="ident">OpenCL</span>;

<span class="comment">// These should only be imported with caution, since they are likely</span>
<span class="comment">// to create a namespace collision.</span>
<span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">error</span>::<span class="ident">Error</span>;

<span class="doccomment">/// A module meant to be glob imported when using Coaster.</span>
<span class="doccomment">///</span>
<span class="doccomment">/// For instance:</span>
<span class="doccomment">///</span>
<span class="doccomment">/// ```</span>
<span class="doccomment">/// use coaster::prelude::*;</span>
<span class="doccomment">/// ```</span>
<span class="doccomment">///</span>
<span class="doccomment">/// This module contains several important traits that provide many</span>
<span class="doccomment">/// of the convenience methods in Coaster, as well as most important types.</span>
<span class="doccomment">/// Another type that is often needed but is likely to cause a name collision</span>
<span class="doccomment">/// when imported is `coaster::Error`.</span>
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">prelude</span> {
    <span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">backend</span>::<span class="kw-2">*</span>;
    <span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">device</span>::{<span class="ident">IDevice</span>, <span class="ident">IMemory</span>};
    <span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">hardware</span>::{<span class="ident">IHardware</span>, <span class="ident">HardwareType</span>};
    <span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">framework</span>::<span class="ident">IFramework</span>;
    <span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">frameworks</span>::<span class="ident">native</span>::<span class="ident">flatbox</span>::<span class="ident">FlatBox</span>;
    <span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">tensor</span>::{<span class="ident">SharedTensor</span>, <span class="ident">TensorDesc</span>, <span class="ident">ITensorDesc</span>, <span class="ident">IntoTensorDesc</span>};
    <span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;native&quot;</span>)]</span>
    <span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">frameworks</span>::<span class="ident">Native</span>;
    <span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;cuda&quot;</span>)]</span>
    <span class="kw">pub</span> <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">frameworks</span>::<span class="ident">Cuda</span>;
    <span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;opencl&quot;</span>)]</span>
    <span class="kw">pub</span> <span class="kw">use</span> <span class="ident">frameworks</span>::<span class="ident">OpenCL</span>;
}
</pre></div>
</section><section id="search" class="content hidden"></section><section class="footer"></section><script>window.rootPath = "../../";window.currentCrate = "coaster";</script><script src="../../aliases.js"></script><script src="../../main.js"></script><script src="../../source-script.js"></script><script src="../../source-files.js"></script><script defer src="../../search-index.js"></script></body></html>